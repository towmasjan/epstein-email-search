"""
Uproszczona wersja aplikacji do wyszukiwania maili Epsteina.

Stabilna, bez duplikacji kodu, z lepszym error handling.
"""
import re

import pandas as pd
import streamlit as st
from datasets import load_dataset

from translation_utils import (
    classify_content_type,
    double_validate_translation,
    extract_email_metadata,
    get_cache_key,
    translate_query_to_english,
    translate_text,
    translate_with_fallback,
)

# Konfiguracja strony
st.set_page_config(page_title="Akta Epsteina - Wyszukiwarka Maili", page_icon="üìß", layout="wide")


# Funkcja pomocnicza do formatowania tekstu
def format_email_text(text, highlight_pattern=None, case_sensitive=False):
    """Formatuje tekst maila z podzia≈Çem na akapity i pod≈õwietleniem."""
    if not text or not text.strip():
        return ""

    # Podziel na akapity
    paragraphs = text.split("\n\n")
    if len(paragraphs) == 1:
        paragraphs = [p for p in text.split("\n") if p.strip()]

    formatted_paragraphs = []
    for para in paragraphs:
        if not para.strip():
            continue

        para = " ".join(para.split())

        # Pod≈õwietl je≈õli jest wzorzec
        if highlight_pattern:
            try:
                pattern = re.compile(re.escape(highlight_pattern), re.IGNORECASE if not case_sensitive else 0)
                para = pattern.sub(
                    lambda m: f"<mark style='background-color: #ffeb3b; padding: 2px 4px; border-radius: 3px; font-weight: bold;'>{m.group()}</mark>",
                    para,
                )
            except (re.error, Exception):
                pass

        formatted_paragraphs.append(
            f"<p style='margin-bottom: 1em; line-height: 1.6; text-align: left; word-wrap: break-word;'>{para}</p>"
        )

    return "\n".join(formatted_paragraphs)


# Funkcja do wy≈õwietlania pojedynczego wyniku
def display_email_result(row, idx, search_query_final, case_sensitive, translation_key_prefix=""):
    """Wy≈õwietla pojedynczy wynik maila."""
    try:
        row_text = str(row.get("text", ""))
        row_filename = str(row.get("filename", "N/A"))

        if not row_text or row_text == "nan":
            return

        # Klasyfikuj typ zawarto≈õci
        content_type, content_label = classify_content_type(row_text)

        # Wybierz ikonƒô
        type_badge = "üìß" if content_type == "email" else ("üìã" if content_type == "metadata" else "üìÑ")

        # WyciƒÖgnij metadane
        metadata = extract_email_metadata(row_text)

        # Zbuduj nag≈Ç√≥wek
        metadata_parts = []
        if metadata["from"] != "N/A":
            metadata_parts.append(f"Od: {metadata['from']}")
        if metadata["to"] != "N/A":
            metadata_parts.append(f"Do: {metadata['to']}")
        if metadata["date"] != "N/A":
            metadata_parts.append(f"Data: {metadata['date']}")

        metadata_str = " | ".join(metadata_parts) if metadata_parts else ""
        occurrences = row_text.lower().count(search_query_final.lower())

        expander_title = f"{type_badge} {row_filename}"
        if content_type != "email":
            expander_title += f" [{content_label}]"
        if metadata_str:
            expander_title += f" | {metadata_str}"
        expander_title += f" ({occurrences} wystƒÖpie≈Ñ)"

        with st.expander(expander_title, expanded=False):
            # Metadane
            if metadata["subject"] != "N/A" or any(
                v != "N/A" for v in [metadata["from"], metadata["to"], metadata["date"]]
            ):
                col1, col2 = st.columns(2)
                with col1:
                    if metadata["from"] != "N/A":
                        st.markdown(f"**üì§ Od:** `{metadata['from'][:50]}{'...' if len(metadata['from']) > 50 else ''}`")
                    if metadata["to"] != "N/A":
                        st.markdown(f"**üì• Do:** `{metadata['to'][:50]}{'...' if len(metadata['to']) > 50 else ''}`")
                with col2:
                    if metadata["date"] != "N/A":
                        st.markdown(f"**üìÖ Data:** `{metadata['date']}`")
                    if metadata["subject"] != "N/A":
                        st.markdown(
                            f"**üìå Temat:** `{metadata['subject'][:50]}{'...' if len(metadata['subject']) > 50 else ''}`"
                        )
                st.divider()

            # Informacja o typie dla nie-maili
            if content_type != "email":
                st.info(f"‚ÑπÔ∏è **Typ zawarto≈õci:** {content_label}")
                st.divider()

            # Oryginalny tekst
            st.markdown("**üá¨üáß Orygina≈Ç (angielski):**")
            display_text = row_text[:5000] if len(row_text) > 5000 else row_text

            formatted_text = format_email_text(
                display_text,
                highlight_pattern=search_query_final if search_query_final.lower() in row_text.lower() else None,
                case_sensitive=case_sensitive,
            )

            st.markdown(
                f"<div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px; border-left: 4px solid #1f77b4; max-height: 500px; overflow-y: auto;'>{formatted_text}</div>",
                unsafe_allow_html=True,
            )

            if len(row_text) > 5000:
                st.caption("‚ö†Ô∏è Wy≈õwietlono pierwsze 5000 znak√≥w. Kliknij 'Przet≈Çumacz' aby zobaczyƒá pe≈Çne t≈Çumaczenie.")

            st.caption(f"üìä D≈Çugo≈õƒá: {len(row_text):,} znak√≥w")

            # T≈Çumaczenie
            translation_key = f"trans_{translation_key_prefix}{idx}_{get_cache_key(row_text)}"
            translate_button_key = f"translate_btn_{translation_key_prefix}{idx}"

            if translation_key in st.session_state:
                # Wy≈õwietl istniejƒÖce t≈Çumaczenie
                st.divider()
                st.markdown("**üáµüá± T≈Çumaczenie (polski):**")
                translated_text = st.session_state[translation_key]

                display_trans = translated_text[:5000] if len(translated_text) > 5000 else translated_text
                formatted_trans = format_email_text(
                    display_trans,
                    highlight_pattern=search_query_final
                    if search_query_final.lower() in translated_text.lower()
                    else None,
                    case_sensitive=case_sensitive,
                )

                st.markdown(
                    f"<div style='background-color: #e8f5e9; padding: 15px; border-radius: 5px; border-left: 4px solid #4caf50; max-height: 500px; overflow-y: auto;'>{formatted_trans}</div>",
                    unsafe_allow_html=True,
                )

                if len(translated_text) > 5000:
                    st.caption("‚ö†Ô∏è Wy≈õwietlono pierwsze 5000 znak√≥w t≈Çumaczenia.")
            else:
                # Przycisk do t≈Çumaczenia
                if st.button("üîÑ Przet≈Çumacz na polski", key=translate_button_key):
                    _handle_translation(row_text, translation_key, search_query_final, case_sensitive)

    except Exception as e:
        st.warning(f"‚ö†Ô∏è B≈ÇƒÖd podczas przetwarzania maila: {e}")


def _handle_translation(row_text, translation_key, search_query_final, case_sensitive):
    """Obs≈Çuguje proces t≈Çumaczenia."""
    progress_container = st.empty()

    with progress_container.container():
        st.info("üîÑ T≈Çumaczenie na polski... To mo≈ºe zajƒÖƒá kilka sekund.")
        progress_bar = st.progress(0)
        status_text = st.empty()

    try:
        # Ograniczenie d≈Çugo≈õci
        text_to_translate = row_text[:3000] if len(row_text) > 3000 else row_text

        status_text.text("üìù Przygotowywanie tekstu...")
        progress_bar.progress(0.1)

        if len(text_to_translate) > 500:
            status_text.text("üìÑ Dzielenie tekstu na fragmenty...")
            progress_bar.progress(0.3)

        status_text.text("üåê T≈Çumaczenie tekstu...")
        progress_bar.progress(0.5)
        translated = translate_text(text_to_translate, None)

        status_text.text("‚úÖ Walidacja t≈Çumaczenia...")
        progress_bar.progress(0.8)

        is_valid, reason = double_validate_translation(text_to_translate, translated)

        progress_bar.progress(1.0)
        progress_container.empty()

        if is_valid:
            st.session_state[translation_key] = translated
            st.success("‚úÖ T≈Çumaczenie zako≈Ñczone pomy≈õlnie!")
            st.rerun()
        else:
            # Fallback
            progress_container.empty()
            st.warning(f"‚ö†Ô∏è T≈Çumaczenie nie przesz≈Ço walidacji: {reason}")

            with progress_container.container():
                st.info("üîÑ Pr√≥bujƒô alternatywnej metody t≈Çumaczenia...")
                fallback_progress = st.progress(0)
                fallback_status = st.empty()

            fallback_status.text("üåê T≈Çumaczenie metodƒÖ alternatywnƒÖ...")
            fallback_progress.progress(0.5)
            fallback_translated = translate_with_fallback(text_to_translate)
            fallback_progress.progress(1.0)
            progress_container.empty()

            is_valid_fallback, reason_fallback = double_validate_translation(text_to_translate, fallback_translated)

            if is_valid_fallback:
                st.session_state[translation_key] = fallback_translated
                st.success("‚úÖ T≈Çumaczenie zako≈Ñczone pomy≈õlnie (metoda alternatywna)!")
                st.rerun()
            else:
                st.error(f"‚ùå Nie uda≈Ço siƒô przet≈Çumaczyƒá: {reason_fallback}")
                st.info("üí° Wy≈õwietlany jest oryginalny tekst po angielsku")

    except Exception as e:
        progress_container.empty()
        st.error(f"‚ùå B≈ÇƒÖd podczas t≈Çumaczenia: {e}")


# Nag≈Ç√≥wek
st.title("üìß Akta Epsteina - Wyszukiwarka Maili")
st.markdown("**Wyszukiwanie i przeglƒÖdanie maili po angielsku**")

# Opis aplikacji
with st.expander("‚ÑπÔ∏è O aplikacji", expanded=False):
    st.markdown(
        """
    ### üìñ Opis

    Ta aplikacja s≈Çu≈ºy do **wyszukiwania i przeglƒÖdania maili** pochodzƒÖcych z publicznego repozytorium
    [Hugging Face](https://huggingface.co/datasets/tensonaut/EPSTEIN_FILES_20K).
    Aplikacja zosta≈Ça stworzona wy≈ÇƒÖcznie w **celach badawczych i edukacyjnych**.

    ### üîç Jak dzia≈Ça program?

    1. **Wyszukiwanie**: Wpisz s≈Çowo kluczowe, nazwisko lub frazƒô w polu wyszukiwania.
       - Mo≈ºesz pisaƒá po **polsku** - aplikacja automatycznie przet≈Çumaczy zapytanie na angielski
       - Mo≈ºesz r√≥wnie≈º pisaƒá bezpo≈õrednio po angielsku

    2. **Wyniki**: Aplikacja wy≈õwietli wszystkie maile zawierajƒÖce wyszukiwane s≈Çowo/frazƒô
       - Ka≈ºdy wynik pokazuje metadane (nadawca, odbiorca, data, temat)
       - Wyszukiwane s≈Çowa sƒÖ **pod≈õwietlone** w tek≈õcie

    3. **T≈Çumaczenie**: Ka≈ºdy mail mo≈ºna przet≈Çumaczyƒá na polski klikajƒÖc przycisk **"üîÑ Przet≈Çumacz na polski"**
       - ‚ö†Ô∏è **Uwaga**: T≈Çumaczenie nie jest idealne, poniewa≈º korzysta z publicznego modelu t≈Çumaczeniowego
         z repozytorium Hugging Face

    ### üë§ Autor

    **PT**

    ---

    *Aplikacja wykorzystuje biblioteki: Streamlit, Hugging Face Transformers, Pandas*
    """
    )

# ≈Åadowanie datasetu
DATASET_NAME = "tensonaut/EPSTEIN_FILES_20K"
SPLIT_NAME = "train"

if "dataset" not in st.session_state:
    with st.spinner("üîÑ ≈Åadowanie zbioru danych..."):
        try:
            dataset = load_dataset(DATASET_NAME, split=SPLIT_NAME)
            st.session_state["dataset"] = dataset
            st.success("‚úÖ Zbi√≥r danych za≈Çadowany!")
        except Exception as e:
            st.error(f"‚ùå B≈ÇƒÖd podczas ≈Çadowania: {str(e)}")
            st.stop()

# G≈Ç√≥wna zawarto≈õƒá
st.header("üîç Wyszukiwanie w mailach")

if "dataset" in st.session_state:
    dataset = st.session_state["dataset"]

    # Cache DataFrame
    if "dataframe" not in st.session_state:
        with st.spinner("üîÑ Konwersja danych do formatu pandas..."):
            try:
                df = dataset.to_pandas()
                st.session_state["dataframe"] = df
            except Exception as e:
                st.error(f"‚ùå B≈ÇƒÖd podczas konwersji do pandas: {e}")
                st.stop()
    else:
        df = st.session_state["dataframe"]

    # Sprawd≈∫ kolumny
    if "text" not in df.columns or "filename" not in df.columns:
        st.error("‚ùå B≈ÇƒÖd: Brak wymaganych kolumn w zbiorze danych")
        st.stop()

    # Wyszukiwarka
    search_query = st.text_input(
        "üîé Szukaj w mailach",
        placeholder="np. 'Epstein', 'Clinton', 'court', 'travel'...",
        help="Wpisz s≈Çowo kluczowe, nazwisko lub frazƒô (mo≈ºesz pisaƒá po polsku - zostanie przet≈Çumaczone)",
    )

    col1, col2 = st.columns(2)
    with col1:
        search_in_text = st.checkbox("Szukaj w tre≈õci", value=True)
    with col2:
        case_sensitive = st.checkbox("Rozr√≥≈ºniaj wielko≈õƒá liter", value=False)

    search_button_clicked = st.button("üîç Szukaj", type="primary", key="search_button")

    # Wyszukiwanie
    if search_button_clicked:
        if not search_query or not search_query.strip():
            st.warning("‚ö†Ô∏è Wpisz zapytanie wyszukiwania")
        else:
            with st.spinner("üîç Przeszukiwanie maili..."):
                try:
                    # T≈Çumaczenie zapytania
                    original_query = search_query.strip()
                    translated_query = translate_query_to_english(original_query)

                    if translated_query != original_query:
                        st.info(f"üî§ Zapytanie przet≈Çumaczone: '{original_query}' ‚Üí '{translated_query}'")
                        search_query_final = translated_query
                    else:
                        search_query_final = original_query

                    # Wyszukiwanie
                    if search_in_text:
                        text_mask = (
                            df["text"]
                            .astype(str)
                            .str.contains(search_query_final, case=case_sensitive, na=False, regex=False)
                        )
                        filtered_df = df[text_mask].copy()
                    else:
                        filtered_df = pd.DataFrame()

                    if len(filtered_df) > 0:
                        # Ograniczenie i klasyfikacja
                        filtered_df_limited = filtered_df.head(100).copy()

                        # Klasyfikuj i sortuj
                        filtered_df_limited["content_type"] = filtered_df_limited["text"].apply(
                            lambda x: classify_content_type(str(x))[0] if pd.notna(x) else "other"
                        )
                        filtered_df_limited["content_label"] = filtered_df_limited["text"].apply(
                            lambda x: classify_content_type(str(x))[1] if pd.notna(x) else "Inny dokument"
                        )

                        type_order = {"email": 0, "metadata": 1, "json": 2, "other": 3}
                        filtered_df_limited["sort_order"] = filtered_df_limited["content_type"].map(type_order)
                        filtered_df_limited = filtered_df_limited.sort_values("sort_order").reset_index(drop=True)
                        filtered_df_limited = filtered_df_limited.drop(columns=["sort_order"])

                        # Zapisz w session_state
                        st.session_state["search_results"] = filtered_df_limited
                        st.session_state["last_search_query"] = search_query_final
                        st.session_state["last_case_sensitive"] = case_sensitive
                        st.session_state["last_search_in_text"] = search_in_text
                        st.session_state["last_original_query"] = original_query

                        st.success(f"‚úÖ Znaleziono {len(filtered_df)} wynik√≥w")

                        # Statystyki
                        type_counts = filtered_df_limited["content_type"].value_counts()
                        stats_parts = []
                        if "email" in type_counts:
                            stats_parts.append(f"üìß Maile: {type_counts['email']}")
                        if "metadata" in type_counts:
                            stats_parts.append(f"üìã Metadane: {type_counts['metadata']}")
                        if "other" in type_counts:
                            stats_parts.append(f"üìÑ Inne: {type_counts['other']}")

                        if stats_parts:
                            st.caption(" | ".join(stats_parts))

                        # Paginacja
                        RESULTS_PER_PAGE = 10
                        total_results = len(filtered_df_limited)
                        total_pages = (total_results + RESULTS_PER_PAGE - 1) // RESULTS_PER_PAGE

                        if total_pages > 1:
                            page_key = "results_page"
                            if page_key not in st.session_state:
                                st.session_state[page_key] = 1

                            col1, col2, col3 = st.columns([1, 2, 1])
                            with col2:
                                page = st.number_input(
                                    "Strona",
                                    min_value=1,
                                    max_value=total_pages,
                                    value=st.session_state.get(page_key, 1),
                                    key=page_key,
                                    help=f"Wy≈õwietlanie {RESULTS_PER_PAGE} wynik√≥w na stronƒô",
                                )

                            st.caption(
                                f"üìÑ Strona {page} z {total_pages} ({RESULTS_PER_PAGE} wynik√≥w na stronƒô, ≈ÇƒÖcznie {total_results} wynik√≥w)"
                            )
                            st.divider()

                            start_idx = (page - 1) * RESULTS_PER_PAGE
                            end_idx = min(start_idx + RESULTS_PER_PAGE, total_results)
                            results_to_show = filtered_df_limited.iloc[start_idx:end_idx]
                        else:
                            page = 1
                            results_to_show = filtered_df_limited

                        # Wy≈õwietl wyniki
                        for idx, row in results_to_show.iterrows():
                            display_email_result(row, idx, search_query_final, case_sensitive)
                    else:
                        st.info("‚ùå Nie znaleziono maili pasujƒÖcych do zapytania")
                        if "search_results" in st.session_state:
                            del st.session_state["search_results"]
                except Exception as e:
                    st.error(f"‚ùå B≈ÇƒÖd podczas wyszukiwania: {e}")
                    st.exception(e)

    # Wy≈õwietl zapisane wyniki je≈õli sƒÖ dostƒôpne
    if (
        "search_results" in st.session_state
        and len(st.session_state["search_results"]) > 0
        and not search_button_clicked
    ):
        filtered_df = st.session_state["search_results"]
        search_query_final = st.session_state.get("last_search_query", "")
        case_sensitive = st.session_state.get("last_case_sensitive", False)

        if len(filtered_df) > 0:
            st.success(f"‚úÖ Znaleziono {len(filtered_df)} wynik√≥w")

            # Paginacja
            RESULTS_PER_PAGE = 10
            total_results = len(filtered_df)
            total_pages = (total_results + RESULTS_PER_PAGE - 1) // RESULTS_PER_PAGE

            if total_pages > 1:
                page_key = "results_page"
                if page_key not in st.session_state:
                    st.session_state[page_key] = 1

                col1, col2, col3 = st.columns([1, 2, 1])
                with col2:
                    page = st.number_input(
                        "Strona",
                        min_value=1,
                        max_value=total_pages,
                        value=st.session_state.get(page_key, 1),
                        key=page_key,
                        help=f"Wy≈õwietlanie {RESULTS_PER_PAGE} wynik√≥w na stronƒô",
                    )

                st.caption(
                    f"üìÑ Strona {page} z {total_pages} ({RESULTS_PER_PAGE} wynik√≥w na stronƒô, ≈ÇƒÖcznie {total_results} wynik√≥w)"
                )
                st.divider()

                page = st.session_state.get("results_page", 1)
                start_idx = (page - 1) * RESULTS_PER_PAGE
                end_idx = min(start_idx + RESULTS_PER_PAGE, total_results)
                results_to_show = filtered_df.iloc[start_idx:end_idx]
            else:
                page = 1
                results_to_show = filtered_df

            # Wy≈õwietl wyniki
            for idx, row in results_to_show.iterrows():
                display_email_result(row, idx, search_query_final, case_sensitive, translation_key_prefix="saved_")

    # Informacja o zbiorze
    st.divider()
    st.caption(f"üìã Zbi√≥r danych: {DATASET_NAME} | Liczba dokument√≥w: {len(df):,}")

else:
    st.warning("‚ö†Ô∏è Zbi√≥r danych nie zosta≈Ç za≈Çadowany. Od≈õwie≈º stronƒô.")

# Footer
st.divider()
st.caption("üìß Akta Epsteina - Wyszukiwarka Maili | Autor: **PT** | Zbudowane z ‚ù§Ô∏è u≈ºywajƒÖc Streamlit i Hugging Face ü§ó")
st.caption("‚ö†Ô∏è Aplikacja s≈Çu≈ºy wy≈ÇƒÖcznie celom badawczym i edukacyjnym. T≈Çumaczenia mogƒÖ zawieraƒá b≈Çƒôdy.")
